[dalton]

# location for job .zip files on disk. Not deleted by dalton; use
#  something like a cron job to prune old files if necessary
job_path = /opt/dalton/jobs

# path for variables files for each engine; not used
#  in this release since the splitting of variables and other
#  configuration options is not currently supported
var_path = /opt/dalton/variables

# root directory for all the rulesets Dalton knows about
ruleset_path = /opt/dalton/rulesets

# temp storage for pcaps, configs, etc. Should be cleaned up by Dalton 
#  and everything in here can be deleted after the job is submitted
temp_path = /tmp/dalton

# IP/host of redis server; dalton_redis is the (resolvable)
#  hostname of the redis docker container
redis_host = dalton_redis

# location of configuration files for the sundry supported engines
engine_conf_path = /opt/dalton/app/static/engine-configs

# timeout (seconds) for keys to expire in Redis for regular (non-teapot)
#  submitted jobs (43200 == 5 days)
redis_expire = 432000

# timeout (seconds) for keys to expire in Redis for teapot
#  jobs (short and stout jobs that are short lived)
teapot_redis_expire = 3720

# time (seconds) for jobs to run before setting timeout status
job_run_timeout = 3600

# API Keys valid for Dalton Agents (currently not used)
api_keys = bmV2ZXIgdW5kZXJlc3RpbWF0ZSB5b3VyIG9wcG9uZW50,ZXhwZWN0IHRoZSB1bmV4cGVjdGVk,dGFrZSBpdCBvdXRzaWRl,UGFpbiBkb24ndCBodXJ0

# location of mergecap binary; needed to combine multiple pcaps for Suricata jobs
mergecap_binary = /usr/bin/mergecap

# program that reads the unified2 binary files and outputs text
u2_analyzer = /usr/local/bin/u2spewfoo.py
